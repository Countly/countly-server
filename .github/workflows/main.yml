# This is a basic workflow to help you get started with Actions

name: CI

# Controls when the workflow will run
on:
  # Triggers the workflow on push or pull request events but only for the master branch
  pull_request:
    branches: [ master, next, release.*, flex, newarchitecture ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      custom_tag:
        description: 'Custom Docker tag (optional)'
        required: false
        default: ''

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "build"
  install:
    # The type of runner that the job will run on
    runs-on: ubuntu-22.04

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v6

      - name: Copy code
        shell: bash
        run: |
          sudo mkdir -p /opt/countly
          touch log/countly-dashboard.log
          touch log/countly-api.log
          cp -rf ./* /opt/countly
        
      - name: Github Actions Azure connection fix
        run: |
          # Workaround for https://github.com/actions/runner-images/issues/675#issuecomment-1381389712
          sudo sed -i 's/azure/us/g' /etc/apt/sources.list
        
      - name: Installing Countly
        shell: bash
        working-directory: /opt/countly
        run: sudo bash ./bin/countly.install.sh

      - name: NodeJS version
        shell: bash
        run: node --version

      - name: NPM version
        shell: bash
        run: npm --version

      - name: Mongo version
        shell: bash
        run: mongosh --version

      - name: Output API Logs
        working-directory: /opt/countly
        if: ${{ always() }}
        run: cat log/countly-api.log

      - name: Output Dashboard Logs
        working-directory: /opt/countly
        if: ${{ always() }}
        run: cat log/countly-dashboard.log

      - name: Output MongoDB Logs
        if: ${{ always() }}
        run: sudo cat /var/log/mongodb/mongod.log

      - name: Output Nginx Logs
        if: ${{ always() }}
        run: sudo cat /var/log/nginx/error.log
  lint:
    runs-on: ubuntu-latest

    services:
      mongodb:
        image: mongo:8.0
        options: >-
          --health-cmd mongosh
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 27017:27017

    container:
      image: countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name  }}
      env:
        COUNTLY_CONFIG__MONGODB_HOST: mongodb
        COUNTLY_CONFIG_API_PREVENT_JOBS: true

    steps:
      - uses: actions/checkout@v6

      - name: Copy code
        shell: bash
        run: cp -rf ./* /opt/countly

      - name: Enable command line
        shell: bash
        run: sudo bash /opt/countly/bin/scripts/detect.init.sh

      - name: ShellCheck
        shell: bash
        run: |
         apt-get update -y
         apt-get -y install shellcheck
         countly shellcheck

      - name: ESLint
        shell: bash
        run: |
         npm install eslint@8.57.0 eslint-plugin-vue@9.31.0 @stylistic/eslint-plugin@2.11.0
         npx eslint .

      - name: Check for any external web resources
        shell: bash
        run: bash bin/scripts/check-external-resources.sh

      - name: NPM install
        shell: bash
        working-directory: /opt/countly
        run: npm install

      - name: Enabling plugins
        shell: bash
        run: cp "./plugins/plugins.default.json" "/opt/countly/plugins/plugins.json"

      - name: DistFiles
        shell: bash
        working-directory: /opt/countly
        run: sudo countly task dist-all
  clickhouse-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: NPM install
        shell: bash
        run: |
          npm install
          cd plugins/clickhouse
          npm install

      - name: Run unit tests
        shell: bash
        run: npm run test:clickhouse:cluster
  unit-tests:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v6

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
      
      - name: NPM install in plugins (skip ab-testing)
        shell: bash
        run: |
            for dir in plugins/*/ ; do
              if [ -f "$dir/package.json" ]; then
                echo "Running npm install in $dir"
                (cd "$dir" && npm install)
              fi
            done

      - name: NPM install
        shell: bash
        run: npm install

      - name: Copy needed files
        shell: bash
        run: |
          cp -rf api/config.sample.js api/config.js
          cp -rf frontend/express/config.sample.js frontend/express/config.js
          cp -rf plugins/plugins.default.json plugins/plugins.json

      - name: Run unit tests
        shell: bash
        run: npm run test:unit
  test-api-core:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Start backend dependencies
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml up -d
          docker compose -f docker-compose.ci.yml ps

      - name: Pull Countly Core image
        run: |
          docker pull countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }}

      - name: Wait for Kafka
        run: |
          echo "Waiting for Kafka..."
          for i in {1..40}; do
            if docker ps --filter "name=kafka" --filter "health=healthy" --format '{{.Names}}' | grep -q kafka; then
              echo "Kafka is healthy!"
              break
            fi
            echo "Kafka not ready yet..."
            sleep 5
          done

      - name: Wait for MongoDB
        run: |
          echo "Waiting for MongoDB to be ready..."
          for i in {1..20}; do
            if docker exec kafka mongosh --host mongodb --eval "db.adminCommand('ping')" &>/dev/null; then
              echo "MongoDB is ready!"
              break
            fi
            echo "Waiting... (attempt $i/20)"
            sleep 2
          done

      - name: Wait for ClickHouse
        run: |
          echo "Waiting for ClickHouse..."
          for i in {1..40}; do
            if curl -s http://localhost:8123/ping | grep -q 'Ok'; then
              echo "ClickHouse is responding to ping!"
              break
            fi
            echo "Still waiting..."
            sleep 5
          done
          
          echo "Verifying ClickHouse can accept queries..."
          for i in {1..20}; do
            if curl -s "http://localhost:8123/?query=SELECT%201" | grep -q '1'; then
              echo "ClickHouse can execute queries!"
              break
            fi
            echo "Waiting for query capability... (attempt $i/20)"
            sleep 3
          done
          
          echo "Creating test database to verify write capability..."
          curl -s "http://localhost:8123/?query=CREATE%20DATABASE%20IF%20NOT%20EXISTS%20countly_drill" || echo "Database creation attempt"
          
          echo "Verifying database exists..."
          curl -s "http://localhost:8123/?query=SHOW%20DATABASES" | grep -q "countly_drill" && echo "✓ Database ready" || echo "Database check failed"

      - name: Verify ClickHouse low-RAM settings
        run: |
          echo "=== ClickHouse Configuration Check ==="
          echo "Max threads:"
          curl -s "http://localhost:8123/?query=SELECT%20value%20FROM%20system.settings%20WHERE%20name%3D'max_threads'" || echo "Query failed"
          echo ""
          echo "Max block size:"
          curl -s "http://localhost:8123/?query=SELECT%20value%20FROM%20system.settings%20WHERE%20name%3D'max_block_size'" || echo "Query failed"
          echo ""
          echo "Max memory usage:"
          curl -s "http://localhost:8123/?query=SELECT%20value%20FROM%20system.settings%20WHERE%20name%3D'max_memory_usage'" || echo "Query failed"
          echo ""
          echo "Input parallel parsing:"
          curl -s "http://localhost:8123/?query=SELECT%20value%20FROM%20system.settings%20WHERE%20name%3D'input_format_parallel_parsing'" || echo "Query failed"
          echo ""
          echo "Config files loaded:"
          docker exec clickhouse ls -la /etc/clickhouse-server/config.d/ || echo "Cannot list config files"

      - name: Wait for Kafka Connect
        run: |
          echo "Waiting for Kafka Connect..."
          for i in {1..40}; do
            if curl -s http://localhost:8083/connectors >/dev/null; then
              echo "Kafka Connect API is ready!"
              break
            fi
            echo "Not ready yet..."
            sleep 5
          done

      - name: Wait for connector-init to complete
        working-directory: bin/datasource
        run: |
          echo "Waiting for connector-init service to complete..."
          for i in {1..60}; do
            STATUS=$(docker inspect connector-init --format='{{.State.Status}}' 2>/dev/null || echo "not_found")
            if [ "$STATUS" = "exited" ]; then
              EXIT_CODE=$(docker inspect connector-init --format='{{.State.ExitCode}}' 2>/dev/null || echo "1")
              if [ "$EXIT_CODE" = "0" ]; then
                echo "connector-init completed successfully!"
                break
              else
                echo "connector-init failed with exit code $EXIT_CODE"
                docker logs connector-init
                exit 1
              fi
            fi
            echo "connector-init status: $STATUS (attempt $i/60)"
            sleep 5
          done
          echo "Verifying connector is running..."
          curl -s http://localhost:8083/connectors/clickhouse-sink/status | head -100

      - name: Create Kafka topic
        run: |
          echo "Creating drill-events topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --create \
            --topic drill-events \
            --partitions 1 \
            --replication-factor 1 \
            --bootstrap-server kafka:29092 || echo "Topic may already exist"
          echo "Verifying topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092

      - name: Wait for Kafka consumer offsets topic
        run: |
          echo "Waiting for __consumer_offsets topic (required for consumer groups)..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092 | grep -q "__consumer_offsets"; then
              echo "__consumer_offsets topic ready!"
              sleep 5
              break
            fi
            echo "Waiting... (attempt $i/30)"
            sleep 2
          done

      - name: Show running services
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml ps
          echo "Backend stack fully operational!"

      - name: Start Countly test container
        run: |
          docker run -d \
            --name countly-test \
            --network datasource_kafka-net \
            -e NODE_ENV=test \
            -e COUNTLY_PLUGINS=mobile,web,desktop,plugins,density,locale,browser,sources,views,license,drill,funnels,retention_segments,flows,cohorts,surveys,remote-config,ab-testing,formulas,activity-map,concurrent_users,logger,systemlogs,populator,reports,crashes,geo,block,users,star-rating,slipping-away-users,compare,server-stats,dbviewer,crash_symbolication,crashes-jira,groups,white-labeling,alerts,times-of-day,compliance-hub,onboarding,active_users,config-transfer,consolidate,data-manager,hooks,dashboards,journey_engine,content,clickhouse,guides,sdk,kafka,oidc,ai-assistant,revenue \
            -e COUNTLY_CONFIG__MONGODB_HOST=mongodb \
            -e COUNTLY_CONFIG__MONGODB_DB=countly \
            -e COUNTLY_CONFIG__MONGODB_PORT=27017 \
            -e COUNTLY_CONFIG__CLICKHOUSE_URL=http://clickhouse:8123 \
            -e COUNTLY_CONFIG__CLICKHOUSE_USERNAME=default \
            -e COUNTLY_CONFIG__CLICKHOUSE_PASSWORD= \
            -e COUNTLY_CONFIG__CLICKHOUSE_DATABASE=countly_drill \
            -e COUNTLY_CONFIG__FILESTORAGE=gridfs \
            -e COUNTLY_CONFIG__DRILL_EVENTS_DRIVER=clickhouse \
            -e COUNTLY_CONFIG__SHARED_CONNECTION=true \
            -e COUNTLY_CONFIG__PATH= \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERPREFERENCE='["clickhouse","mongodb"]' \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_MONGODB_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_CLICKHOUSE_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_FAILONCONNECTIONERROR=true \
            -e COUNTLY_CONFIG__DATABASE_DEBUG=true \
            -e COUNTLY_CONFIG__DATABASE_COMPARISONLOGS_MODE=disabled \
            -e COUNTLY_CONFIG__EVENTSINK_SINKS='["kafka","mongo"]' \
            -e COUNTLY_CONFIG__KAFKA_ENABLED=true \
            -e COUNTLY_CONFIG__KAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_DRILLEVENTSTOPIC=drill-events \
            -e COUNTLY_CONFIG__KAFKA_CLUSTER_NAME=cly-kafka \
            -e COUNTLY_CONFIG__KAFKA_NAMESPACE=kafka \
            -e COUNTLY_CONFIG__KAFKA_GROUPIDPREFIX=cly_ \
            -e COUNTLY_CONFIG__KAFKA_PARTITIONS=1 \
            -e COUNTLY_CONFIG__KAFKA_REPLICATIONFACTOR=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_AUTOOFFSETRESET=earliest \
            -e COUNTLY_CONFIG__RELOADCONFIGAFTER=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_LINGERMS=0 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_RETRIES=1 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_REQUESTTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_CONNECTIONTIMEOUTMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_INITIALRETRYTIME=50 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_MAXRETRYTIME=500 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHSIZE=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHNUMMESSAGES=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXMESSAGES=100 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXKBYTES=1024 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_COMPRESSIONLEVEL=0 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_MESSAGETIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_DELIVERYTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMINBYTES=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXWAITMS=10 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXBYTES=1048576 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPARTITIONFETCHBYTES=262144 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_PARTITIONSCONSUMEDCONCURRENTLY=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_SESSIONTIMEOUTMS=10000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_HEARTBEATINTERVALMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPOLLINTERVALMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_REBALANCETIMEOUTMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONBEHAVIOR=skip \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONMETRICS=true \
            -e COUNTLY_SETTINGS__LOGS__DEBUG='' \
            -e COUNTLY_SETTINGS__LOGS__DEFAULT='warn' \
            -e COUNTLY_SETTINGS__FUNNELS__FUNNEL_CACHING=false \
            -e COUNTLY_SETTINGS__DRILL__RECORD_META=true \
            -e COUNTLY_SETTINGS__API__BATCH_PROCESSING=false \
            -e COUNTLY_SETTINGS__API__BATCH_READ_PROCESSING=false \
            countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }} \
            sleep infinity

      - name: Copy plugins and scripts into container
        run: |
          docker cp ./. countly-test:/opt/countly/
          docker exec countly-test bash -c "
            bash /opt/countly/bin/scripts/countly.prepare.ce.tests.sh
            cp -rf /opt/countly/plugins/plugins.default.json /opt/countly/plugins/plugins.json
            rm -rf /opt/countly/test/4.plugins
          "
          echo 'Code copied into container.'

      - name: Install plugins
        run: |
          docker exec countly-test bash -c "
            node /opt/countly/bin/scripts/install_plugins.js --force --skip-production
            cd /opt/countly
            npm install
          "

      - name: Verify Kafka topics created
        run: |
          echo "Checking if drill-events topic was created..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092 | grep -q "drill-events"; then
              echo "drill-events topic found!"
              docker exec kafka /opt/kafka/bin/kafka-topics.sh --describe --topic drill-events --bootstrap-server kafka:29092
              break
            fi
            echo "Waiting for topic creation... (attempt $i/30)"
            sleep 2
          done

      - name: Wait for data pipeline stabilization
        run: |
          echo "Verifying Kafka Connect connector is running..."
          for i in {1..30}; do
            CONNECTOR_STATE=$(curl -s http://localhost:8083/connectors/clickhouse-sink/status | grep -o '"state":"[^"]*"' | head -1 | cut -d'"' -f4 || echo "unknown")
            if [ "$CONNECTOR_STATE" = "RUNNING" ]; then
              echo "✓ Connector is running, pipeline ready!"
              break
            fi
            echo "Connector state: $CONNECTOR_STATE (attempt $i/30)"
            sleep 1
          done

      - name: Run tests
        run: |
          docker exec -i countly-test bash -c "
            cd /opt/countly
            /sbin/my_init &
            node /opt/countly/bin/scripts/test.connection.js
            npx grunt mochaTest
          "

      - name: Cleanup
        if: always()
        run: |
          docker stop countly-test || true
          docker rm countly-test || true
          cd bin/datasource
          docker compose -f docker-compose.ci.yml down -v || true
  test-api-plugins:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Start backend dependencies
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml up -d
          docker compose -f docker-compose.ci.yml ps

      - name: Pull Countly Core image
        run: |
          docker pull countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }}

      - name: Wait for Kafka
        run: |
          echo "Waiting for Kafka..."
          for i in {1..40}; do
            if docker ps --filter "name=kafka" --filter "health=healthy" --format '{{.Names}}' | grep -q kafka; then
              echo "Kafka is healthy!"
              break
            fi
            echo "Kafka not ready yet..."
            sleep 5
          done

      - name: Wait for MongoDB
        run: |
          echo "Waiting for MongoDB to be ready..."
          for i in {1..20}; do
            if docker exec kafka mongosh --host mongodb --eval "db.adminCommand('ping')" &>/dev/null; then
              echo "MongoDB is ready!"
              break
            fi
            echo "Waiting... (attempt $i/20)"
            sleep 2
          done

      - name: Wait for ClickHouse
        run: |
          echo "Waiting for ClickHouse..."
          for i in {1..40}; do
            if curl -s http://localhost:8123/ping | grep -q 'Ok'; then
              echo "ClickHouse is responding to ping!"
              break
            fi
            echo "Still waiting..."
            sleep 5
          done
          
          echo "Verifying ClickHouse can accept queries..."
          for i in {1..20}; do
            if curl -s "http://localhost:8123/?query=SELECT%201" | grep -q '1'; then
              echo "ClickHouse can execute queries!"
              break
            fi
            echo "Waiting for query capability... (attempt $i/20)"
            sleep 3
          done
          
          echo "Creating test database to verify write capability..."
          curl -s "http://localhost:8123/?query=CREATE%20DATABASE%20IF%20NOT%20EXISTS%20countly_drill" || echo "Database creation attempt"
          sleep 2
          
          echo "Verifying database exists..."
          curl -s "http://localhost:8123/?query=SHOW%20DATABASES" | grep -q "countly_drill" && echo "✓ Database ready" || echo "Database check failed"

      - name: Wait for Kafka Connect
        run: |
          echo "Waiting for Kafka Connect..."
          for i in {1..40}; do
            if curl -s http://localhost:8083/connectors >/dev/null; then
              echo "Kafka Connect API is ready!"
              break
            fi
            echo "Not ready yet..."
            sleep 5
          done

      - name: Wait for connector-init to complete
        working-directory: bin/datasource
        run: |
          echo "Waiting for connector-init service to complete..."
          for i in {1..60}; do
            STATUS=$(docker inspect connector-init --format='{{.State.Status}}' 2>/dev/null || echo "not_found")
            if [ "$STATUS" = "exited" ]; then
              EXIT_CODE=$(docker inspect connector-init --format='{{.State.ExitCode}}' 2>/dev/null || echo "1")
              if [ "$EXIT_CODE" = "0" ]; then
                echo "connector-init completed successfully!"
                break
              else
                echo "connector-init failed with exit code $EXIT_CODE"
                docker logs connector-init
                exit 1
              fi
            fi
            echo "connector-init status: $STATUS (attempt $i/60)"
            sleep 5
          done
          echo "Verifying connector is running..."
          curl -s http://localhost:8083/connectors/clickhouse-sink/status | head -100

      - name: Create Kafka topic
        run: |
          echo "Creating drill-events topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --create \
            --topic drill-events \
            --partitions 1 \
            --replication-factor 1 \
            --bootstrap-server kafka:29092 || echo "Topic may already exist"
          echo "Verifying topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092

      - name: Wait for Kafka consumer offsets topic
        run: |
          echo "Waiting for __consumer_offsets topic (required for consumer groups)..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092 | grep -q "__consumer_offsets"; then
              echo "__consumer_offsets topic ready!"
              sleep 5
              break
            fi
            echo "Waiting... (attempt $i/30)"
            sleep 2
          done

      - name: Show running services
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml ps
          echo "Backend stack fully operational!"

      - name: Start Countly test container
        run: |
          docker run -d \
            --name countly-test \
            --network datasource_kafka-net \
            -e NODE_ENV=test \
            -e COUNTLY_PLUGINS=mobile,web,desktop,plugins,density,locale,browser,sources,views,license,drill,funnels,retention_segments,flows,cohorts,surveys,remote-config,ab-testing,formulas,activity-map,concurrent_users,logger,systemlogs,populator,reports,crashes,geo,block,users,star-rating,slipping-away-users,compare,server-stats,dbviewer,crash_symbolication,crashes-jira,groups,white-labeling,alerts,times-of-day,compliance-hub,onboarding,active_users,config-transfer,consolidate,data-manager,hooks,dashboards,journey_engine,content,clickhouse,guides,sdk,kafka,oidc,ai-assistant,revenue \
            -e COUNTLY_CONFIG__MONGODB_HOST=mongodb \
            -e COUNTLY_CONFIG__MONGODB_DB=countly \
            -e COUNTLY_CONFIG__MONGODB_PORT=27017 \
            -e COUNTLY_CONFIG__CLICKHOUSE_URL=http://clickhouse:8123 \
            -e COUNTLY_CONFIG__CLICKHOUSE_USERNAME=default \
            -e COUNTLY_CONFIG__CLICKHOUSE_PASSWORD= \
            -e COUNTLY_CONFIG__CLICKHOUSE_DATABASE=countly_drill \
            -e COUNTLY_CONFIG__FILESTORAGE=gridfs \
            -e COUNTLY_CONFIG__DRILL_EVENTS_DRIVER=clickhouse \
            -e COUNTLY_CONFIG__SHARED_CONNECTION=true \
            -e COUNTLY_CONFIG__PATH= \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERPREFERENCE='["clickhouse","mongodb"]' \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_MONGODB_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_CLICKHOUSE_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_FAILONCONNECTIONERROR=true \
            -e COUNTLY_CONFIG__DATABASE_DEBUG=true \
            -e COUNTLY_CONFIG__DATABASE_COMPARISONLOGS_MODE=disabled \
            -e COUNTLY_CONFIG__EVENTSINK_SINKS='["kafka","mongo"]' \
            -e COUNTLY_CONFIG__KAFKA_ENABLED=true \
            -e COUNTLY_CONFIG__KAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_DRILLEVENTSTOPIC=drill-events \
            -e COUNTLY_CONFIG__KAFKA_CLUSTER_NAME=cly-kafka \
            -e COUNTLY_CONFIG__KAFKA_NAMESPACE=kafka \
            -e COUNTLY_CONFIG__KAFKA_GROUPIDPREFIX=cly_ \
            -e COUNTLY_CONFIG__KAFKA_PARTITIONS=1 \
            -e COUNTLY_CONFIG__KAFKA_REPLICATIONFACTOR=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_AUTOOFFSETRESET=earliest \
            -e COUNTLY_CONFIG__RELOADCONFIGAFTER=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_LINGERMS=0 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_RETRIES=1 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_REQUESTTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_CONNECTIONTIMEOUTMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_INITIALRETRYTIME=50 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_MAXRETRYTIME=500 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHSIZE=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHNUMMESSAGES=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXMESSAGES=100 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXKBYTES=1024 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_COMPRESSIONLEVEL=0 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_MESSAGETIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_DELIVERYTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMINBYTES=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXWAITMS=10 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXBYTES=1048576 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPARTITIONFETCHBYTES=262144 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_PARTITIONSCONSUMEDCONCURRENTLY=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_SESSIONTIMEOUTMS=10000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_HEARTBEATINTERVALMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPOLLINTERVALMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_REBALANCETIMEOUTMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONBEHAVIOR=skip \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONMETRICS=true \
            -e COUNTLY_SETTINGS__LOGS__DEBUG='' \
            -e COUNTLY_SETTINGS__LOGS__DEFAULT='warn' \
            -e COUNTLY_SETTINGS__FUNNELS__FUNNEL_CACHING=false \
            -e COUNTLY_SETTINGS__DRILL__RECORD_META=true \
            -e COUNTLY_SETTINGS__API__BATCH_PROCESSING=false \
            -e COUNTLY_SETTINGS__API__BATCH_READ_PROCESSING=false \
            countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }} \
            sleep infinity

      - name: Copy plugins and scripts into container
        run: |
          docker cp ./. countly-test:/opt/countly/
          echo 'Code copied into container.'

      - name: Prepare tests
        run: |
          docker exec countly-test bash -c "
            sed -i 's/mongosh --quiet/mongosh --host mongodb --quiet/' /opt/countly/bin/backup/run.sh && sed -i 's/mongoimport --db/mongoimport --host mongodb --db/' /opt/countly/bin/backup/run.sh
            cp -rf /opt/countly/plugins/plugins.default.json /opt/countly/plugins/plugins.json
            bash /opt/countly/bin/scripts/countly.prepare.ce.plugins.tests.sh
          "
      - name: Install plugins
        run: |
          docker exec countly-test bash -c "
            node /opt/countly/bin/scripts/install_plugins.js --force --skip-production
            cd /opt/countly
            npm install
          "

      - name: Verify Kafka topics created
        run: |
          echo "Checking if drill-events topic was created..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092 | grep -q "drill-events"; then
              echo "drill-events topic found!"
              docker exec kafka /opt/kafka/bin/kafka-topics.sh --describe --topic drill-events --bootstrap-server kafka:29092
              break
            fi
            echo "Waiting for topic creation... (attempt $i/30)"
            sleep 2
          done

      - name: Wait for data pipeline stabilization
        run: |
          echo "Verifying Kafka Connect connector is running..."
          for i in {1..30}; do
            CONNECTOR_STATE=$(curl -s http://localhost:8083/connectors/clickhouse-sink/status | grep -o '"state":"[^"]*"' | head -1 | cut -d'"' -f4 || echo "unknown")
            if [ "$CONNECTOR_STATE" = "RUNNING" ]; then
              echo "✓ Connector is running, pipeline ready!"
              break
            fi
            echo "Connector state: $CONNECTOR_STATE (attempt $i/30)"
            sleep 1
          done

      - name: Run tests
        run: |
          docker exec -i countly-test bash -c "
            cd /opt/countly
            /sbin/my_init &
            node /opt/countly/bin/scripts/test.connection.js
            npx grunt mochaTest
          "

      - name: Cleanup
        if: always()
        run: |
          docker stop countly-test || true
          docker rm countly-test || true
          cd bin/datasource
          docker compose -f docker-compose.ci.yml down -v || true
          
  ui-tests:
    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        test_type: [dashboard, onboarding, sdk]

    steps:
      - uses: actions/checkout@v6

      - name: Check docker compose version
        run: |
          docker compose version

      - name: Start backend dependencies
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml up -d
          docker compose -f docker-compose.ci.yml ps

      - name: Pull Countly Core image
        run: |
          docker pull countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }}

      - name: Wait for Kafka
        run: |
          echo "Waiting for Kafka..."
          for i in {1..40}; do
            if docker ps --filter "name=kafka" --filter "health=healthy" --format '{{.Names}}' | grep -q kafka; then
              echo "Kafka is healthy!"
              break
            fi
            echo "Kafka not ready yet..."
            sleep 5
          done

      - name: Wait for MongoDB
        run: |
          echo "Waiting for MongoDB to be ready..."
          for i in {1..20}; do
            if docker exec kafka mongosh --host mongodb --eval "db.adminCommand('ping')" &>/dev/null; then
              echo "MongoDB is ready!"
              break
            fi
            echo "Waiting... (attempt $i/20)"
            sleep 2
          done

      - name: Wait for ClickHouse
        run: |
          echo "Waiting for ClickHouse..."
          for i in {1..40}; do
            if curl -s http://localhost:8123/ping | grep -q 'Ok'; then
              echo "ClickHouse is responding to ping!"
              break
            fi
            echo "Still waiting..."
            sleep 5
          done
          
          echo "Verifying ClickHouse can accept queries..."
          for i in {1..20}; do
            if curl -s "http://localhost:8123/?query=SELECT%201" | grep -q '1'; then
              echo "ClickHouse can execute queries!"
              break
            fi
            echo "Waiting for query capability... (attempt $i/20)"
            sleep 3
          done
          
          echo "Creating test database to verify write capability..."
          curl -s "http://localhost:8123/?query=CREATE%20DATABASE%20IF%20NOT%20EXISTS%20countly_drill" || echo "Database creation attempt"
          sleep 2
          
          echo "Verifying database exists..."
          curl -s "http://localhost:8123/?query=SHOW%20DATABASES" | grep -q "countly_drill" && echo "✓ Database ready" || echo "Database check failed"

      - name: Wait for Kafka Connect
        run: |
          echo "Waiting for Kafka Connect..."
          for i in {1..40}; do
            if curl -s http://localhost:8083/connectors >/dev/null; then
              echo "Kafka Connect API is ready!"
              break
            fi
            echo "Not ready yet..."
            sleep 5
          done

      - name: Wait for connector-init to complete
        working-directory: bin/datasource
        run: |
          echo "Waiting for connector-init service to complete..."
          for i in {1..60}; do
            STATUS=$(docker inspect connector-init --format='{{.State.Status}}' 2>/dev/null || echo "not_found")
            if [ "$STATUS" = "exited" ]; then
              EXIT_CODE=$(docker inspect connector-init --format='{{.State.ExitCode}}' 2>/dev/null || echo "1")
              if [ "$EXIT_CODE" = "0" ]; then
                echo "connector-init completed successfully!"
                break
              else
                echo "connector-init failed with exit code $EXIT_CODE"
                docker logs connector-init
                exit 1
              fi
            fi
            echo "connector-init status: $STATUS (attempt $i/60)"
            sleep 5
          done
          echo "Verifying connector is running..."
          curl -s http://localhost:8083/connectors/clickhouse-sink/status | head -100

      - name: Create Kafka topic
        run: |
          echo "Creating drill-events topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --create \
            --topic drill-events \
            --partitions 1 \
            --replication-factor 1 \
            --bootstrap-server kafka:29092 || echo "Topic may already exist"
          echo "Verifying topic..."
          docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092

      - name: Wait for Kafka consumer offsets topic
        run: |
          echo "Waiting for __consumer_offsets topic (required for consumer groups)..."
          for i in {1..30}; do
            if docker exec kafka /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server kafka:29092 | grep -q "__consumer_offsets"; then
              echo "__consumer_offsets topic ready!"
              sleep 5
              break
            fi
            echo "Waiting... (attempt $i/30)"
            sleep 2
          done

      - name: Show running services
        working-directory: bin/datasource
        run: |
          docker compose -f docker-compose.ci.yml ps
          echo "Backend stack fully operational!"

      - name: Start Countly UI test container
        run: |
           docker run -d \
            --name countly-test \
            --network datasource_kafka-net \
            -e NODE_ENV=test \
            -e COUNTLY_PLUGINS=mobile,web,desktop,plugins,density,locale,browser,sources,views,license,drill,funnels,retention_segments,flows,cohorts,surveys,remote-config,ab-testing,formulas,activity-map,concurrent_users,logger,systemlogs,populator,reports,crashes,geo,block,users,star-rating,slipping-away-users,compare,server-stats,dbviewer,crash_symbolication,crashes-jira,groups,white-labeling,alerts,times-of-day,compliance-hub,onboarding,active_users,config-transfer,consolidate,data-manager,hooks,dashboards,journey_engine,content,clickhouse,guides,sdk,kafka,oidc,ai-assistant,revenue \
            -e COUNTLY_CONFIG__MONGODB_HOST=mongodb \
            -e COUNTLY_CONFIG__MONGODB_DB=countly \
            -e COUNTLY_CONFIG__MONGODB_PORT=27017 \
            -e COUNTLY_CONFIG__CLICKHOUSE_URL=http://clickhouse:8123 \
            -e COUNTLY_CONFIG__CLICKHOUSE_USERNAME=default \
            -e COUNTLY_CONFIG__CLICKHOUSE_PASSWORD= \
            -e COUNTLY_CONFIG__CLICKHOUSE_DATABASE=countly_drill \
            -e COUNTLY_CONFIG__FILESTORAGE=gridfs \
            -e COUNTLY_CONFIG__DRILL_EVENTS_DRIVER=clickhouse \
            -e COUNTLY_CONFIG__SHARED_CONNECTION=true \
            -e COUNTLY_CONFIG__PATH= \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERPREFERENCE='["clickhouse","mongodb"]' \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_MONGODB_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_ADAPTERS_CLICKHOUSE_ENABLED=true \
            -e COUNTLY_CONFIG__DATABASE_FAILONCONNECTIONERROR=true \
            -e COUNTLY_CONFIG__DATABASE_DEBUG=true \
            -e COUNTLY_CONFIG__DATABASE_COMPARISONLOGS_MODE=disabled \
            -e COUNTLY_CONFIG__EVENTSINK_SINKS='["kafka","mongo"]' \
            -e COUNTLY_CONFIG__KAFKA_ENABLED=true \
            -e COUNTLY_CONFIG__KAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_BROKERS='["kafka:29092"]' \
            -e COUNTLY_CONFIG__KAFKA_DRILLEVENTSTOPIC=drill-events \
            -e COUNTLY_CONFIG__KAFKA_CLUSTER_NAME=cly-kafka \
            -e COUNTLY_CONFIG__KAFKA_NAMESPACE=kafka \
            -e COUNTLY_CONFIG__KAFKA_GROUPIDPREFIX=cly_ \
            -e COUNTLY_CONFIG__KAFKA_PARTITIONS=1 \
            -e COUNTLY_CONFIG__KAFKA_REPLICATIONFACTOR=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_AUTOOFFSETRESET=earliest \
            -e COUNTLY_CONFIG__RELOADCONFIGAFTER=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_LINGERMS=0 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_RETRIES=1 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_REQUESTTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_CONNECTIONTIMEOUTMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_INITIALRETRYTIME=50 \
            -e COUNTLY_CONFIG__KAFKA_RDKAFKA_MAXRETRYTIME=500 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHSIZE=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_BATCHNUMMESSAGES=1 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXMESSAGES=100 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_QUEUEBUFFERINGMAXKBYTES=1024 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_COMPRESSIONLEVEL=0 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_MESSAGETIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_PRODUCER_DELIVERYTIMEOUTMS=5000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMINBYTES=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXWAITMS=10 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_FETCHMAXBYTES=1048576 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPARTITIONFETCHBYTES=262144 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_PARTITIONSCONSUMEDCONCURRENTLY=1 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_SESSIONTIMEOUTMS=10000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_HEARTBEATINTERVALMS=3000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_MAXPOLLINTERVALMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_REBALANCETIMEOUTMS=30000 \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONBEHAVIOR=skip \
            -e COUNTLY_CONFIG__KAFKA_CONSUMER_INVALIDJSONMETRICS=true \
            -e COUNTLY_SETTINGS__LOGS__DEBUG='' \
            -e COUNTLY_SETTINGS__LOGS__DEFAULT='warn' \
            countly/countly-core:pipelines-${{ inputs.custom_tag || github.base_ref || github.ref_name }} \
            sleep infinity

      - name: Install Chrome
        run: |
          docker exec countly-test bash -c "
            apt update
            apt install -y libgtk2.0-0 libgtk-3-0 libgbm-dev libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 libxtst6 xauth xvfb wget
            wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb -O /tmp/chrome.deb
            apt install -y /tmp/chrome.deb
          "

      - name: Install Sharp dependencies for image processing
        run: |
          docker exec countly-test bash -c "
            export DEBIAN_FRONTEND=noninteractive
            apt-get update -y
            apt-get install -y libvips-dev
          "

      - name: Copy plugins and scripts into container
        run: |
          docker cp ./. countly-test:/opt/countly/
          docker exec countly-test bash -c "
            rm -rf /opt/countly/plugins/old-ui-compatibility
            cp /opt/countly/frontend/express/config.sample.js /opt/countly/frontend/express/config.js
            cp /opt/countly/frontend/express/public/javascripts/countly/countly.config.sample.js /opt/countly/frontend/express/public/javascripts/countly/countly.config.js
          "
          echo 'Code copied into container.'

      - name: Prepare files to use correct MongoDB and ClickHouse hosts
        run: |
          docker exec countly-test bash -c "
            sed -i 's/mongosh --quiet/mongosh --host mongodb --quiet/' /opt/countly/bin/backup/import_events.sh
            sed -i 's/mongoimport --db/mongoimport --host mongodb --db/' /opt/countly/bin/backup/import_events.sh
            bash /opt/countly/bin/backup/import_events.sh
          "

      - name: Install plugins
        run: |
          docker exec countly-test bash -c "
            cat /opt/countly/plugins/plugins.default.json
            cp -rf /opt/countly/plugins/plugins.default.json /opt/countly/plugins/plugins.json
            cat /opt/countly/plugins/plugins.json
            node /opt/countly/bin/scripts/install_plugins.js --force
            npm install
          "

      - name: Prepare environment
        shell: bash
        run: |
          docker exec countly-test bash -c "
            cd /opt/countly
            bash bin/backup/import_events.sh
            bash bin/scripts/countly.prepare.ce.tests.sh
            if [ \"${{ matrix.test_type }}\" = \"dashboard\" ]; then
              countly add_user '${{ secrets.CYPRESS_USER_EMAIL }}' '${{ secrets.CYPRESS_USER_PASSWORD }}'
              mongosh --host mongodb --eval 'db.getSiblingDB(\"countly\").members.updateOne({username: \"${{ secrets.CYPRESS_USER_EMAIL }}\"}, {\$set: {username: \"${{ secrets.CYPRESS_USER_USERNAME }}\", subscribe_newsletter: true}});'
              mongosh --host mongodb --eval 'db.getSiblingDB(\"countly\").plugins.updateOne({_id: \"plugins\"}, {\$set: {\"frontend.countly_tracking\": true}});'
            fi
            cd ui-tests
            echo '{\"username\": \"${{ secrets.CYPRESS_USER_USERNAME }}\",\"email\": \"${{ secrets.CYPRESS_USER_EMAIL }}\",\"password\": \"${{ secrets.CYPRESS_USER_PASSWORD }}\"}' > cypress/fixtures/user.json
            sed -i 's/00000000-0000-0000-0000-000000000000/${{ secrets.CYPRESS_KEY }}/g' package.json
            cp cypress.config.sample.js cypress.config.js
            sed -i 's/000000/${{ secrets.CYPRESS_PROJECT_ID }}/g' cypress.config.js
          "

      - name: Run UI tests
        run: |
          docker exec countly-test bash -c "
            cd /opt/countly
            /sbin/my_init &
            node /opt/countly/bin/scripts/test.connection.js
            cd ui-tests
            npm install
            if [ \"${{ matrix.test_type }}\" = \"dashboard\" ]; then
              xvfb-run --auto-servernum --server-args=\"-screen 0 1280x1024x24\" npm run cy:run:dashboard
            elif [ \"${{ matrix.test_type }}\" = \"sdk\" ]; then
              xvfb-run --auto-servernum --server-args=\"-screen 0 1280x1024x24\" npm run cy:run:sdk
            else
              xvfb-run --auto-servernum --server-args=\"-screen 0 1280x1024x24\" npm run cy:run:onboarding
            fi
          " 2>&1

      - name: Upload UI tests artifacts
        if: ${{ failure() }}
        run: |
          docker exec countly-test bash -c "
            cd /opt/countly/ui-tests/cypress
            ARTIFACT_ARCHIVE_NAME=\"\$(date '+%Y%m%d-%H.%M')_countly-server_CI#${{ github.run_number }}_${{ matrix.test_type }}.tar.gz\"

            mkdir -p screenshots videos downloads
            find screenshots videos downloads -type d -empty -delete
          
            TAR_TARGETS=\$(ls -d screenshots videos downloads 2>/dev/null || true)
          
            tar zcvf \"\$ARTIFACT_ARCHIVE_NAME\" \$TAR_TARGETS
            curl -o /tmp/uploader.log -u \"${{ secrets.BOX_UPLOAD_AUTH }}\" \"${{ secrets.BOX_UPLOAD_PATH }}\" -T \"\$ARTIFACT_ARCHIVE_NAME\"
          "
