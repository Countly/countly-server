apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaConnect
metadata:
  name: connect-ch
  namespace: kafka
  annotations:
    strimzi.io/use-connector-resources: "true"
spec:
  version: 4.0.0
  image: gcr.io/countly-dev-313620/kafka-connect-clickhouse:0.47.0-kafka-4.0.0-ch-1.3.2
  replicas: 1
  bootstrapServers: demo-kafka-kafka-bootstrap:9092

  # Worker configuration (Strimzi blocks plugin.path etc.)
  config:
    group.id: connect-ch
    config.storage.topic: connect_ch_configs
    offset.storage.topic: connect_ch_offsets
    status.storage.topic: connect_ch_status
    config.storage.replication.factor: 3
    offset.storage.replication.factor: 3
    status.storage.replication.factor: 3
    config.storage.partitions: 1
    offset.storage.partitions: 25
    status.storage.partitions: 5

    # Converters
    key.converter: org.apache.kafka.connect.storage.StringConverter
    value.converter: org.apache.kafka.connect.json.JsonConverter
    value.converter.schemas.enable: "false"

    # Allow per-connector consumer overrides like consumer.override.max.poll.records
    connector.client.config.override.policy: All

    # Enable EnvVar config provider so `${env:VAR}` is usable in connector configs
    config.providers: env
    config.providers.env.class: org.apache.kafka.common.config.provider.EnvVarConfigProvider

  # JVM & resources for Connect workers
  jvmOptions:
    "-Xms": "5g"
    "-Xmx": "5g"
  resources:
    requests: { cpu: "2", memory: "8Gi" }
    limits:   { cpu: "2", memory: "8Gi" }   # Guaranteed QoS

  # Using pre-built image with ClickHouse connector included
  # Image contains clickhouse-kafka-connect v1.3.2 in /opt/kafka/plugins/

  template:
    connectContainer:
      env:
        - name: CLICKHOUSE_HOST
          valueFrom: { configMapKeyRef: { name: connect-env, key: CLICKHOUSE_HOST } }
        - name: CLICKHOUSE_PORT
          valueFrom: { configMapKeyRef: { name: connect-env, key: CLICKHOUSE_PORT } }
        - name: CLICKHOUSE_SSL
          valueFrom: { configMapKeyRef: { name: connect-env, key: CLICKHOUSE_SSL } }
        - name: CLICKHOUSE_DB
          valueFrom: { configMapKeyRef: { name: connect-env, key: CLICKHOUSE_DB } }
        - name: CLICKHOUSE_USER
          valueFrom: { secretKeyRef: { name: clickhouse-auth, key: username } }
        - name: CLICKHOUSE_PASSWORD
          valueFrom: { secretKeyRef: { name: clickhouse-auth, key: password } }

        # ClickHouse connector settings
        - name: EXACTLY_ONCE
          valueFrom: { configMapKeyRef: { name: connect-env, key: EXACTLY_ONCE } }
        - name: ERRORS_RETRY_TIMEOUT
          valueFrom: { configMapKeyRef: { name: connect-env, key: ERRORS_RETRY_TIMEOUT } }
        - name: ERRORS_TOLERANCE
          valueFrom: { configMapKeyRef: { name: connect-env, key: ERRORS_TOLERANCE } }
        
        # Performance tuning environment variables  
        - name: KAFKA_CONSUMER_FETCH_MIN_BYTES
          valueFrom: { configMapKeyRef: { name: connect-env, key: KAFKA_CONSUMER_FETCH_MIN_BYTES } }
        - name: KAFKA_CONSUMER_MAX_POLL_RECORDS
          valueFrom: { configMapKeyRef: { name: connect-env, key: KAFKA_CONSUMER_MAX_POLL_RECORDS } }
        - name: KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES
          valueFrom: { configMapKeyRef: { name: connect-env, key: KAFKA_CONSUMER_MAX_PARTITION_FETCH_BYTES } }
        - name: KAFKA_CONSUMER_FETCH_MAX_BYTES
          valueFrom: { configMapKeyRef: { name: connect-env, key: KAFKA_CONSUMER_FETCH_MAX_BYTES } }
    pod:

      # Optional: keep Connect off broker nodes
      tolerations:
        - key: dedicated
          operator: Equal
          value: connect
          effect: NoSchedule
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                - key: role
                  operator: In
                  values: ["connect"]
