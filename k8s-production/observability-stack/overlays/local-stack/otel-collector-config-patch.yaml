# Patch to add local Prometheus exporter to OTEL collector
apiVersion: v1
kind: ConfigMap
metadata:
  name: otel-collector-config
  namespace: countly-observability
data:
  otel-collector.yaml: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # Prometheus receiver for scraping metrics from Countly services
      prometheus:
        config:
          scrape_configs:
            - job_name: 'countly-api'
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names:
                      - countly
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name]
                  action: keep
                  regex: countly-api
                - source_labels: [__meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: http
                - target_label: __metrics_path__
                  replacement: /o/metrics
                - source_labels: [__meta_kubernetes_pod_name]
                  target_label: pod
                - source_labels: [__meta_kubernetes_namespace]
                  target_label: namespace
            
            - job_name: 'countly-frontend'
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names:
                      - countly
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name]
                  action: keep
                  regex: countly-frontend
                - source_labels: [__meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: http
                - target_label: __metrics_path__
                  replacement: /o/metrics
                - source_labels: [__meta_kubernetes_pod_name]
                  target_label: pod
                - source_labels: [__meta_kubernetes_namespace]
                  target_label: namespace


      # Collect host metrics from nodes
      hostmetrics:
        collection_interval: 30s
        scrapers:
          cpu:
          memory:
          load:
          disk:
          filesystem:
          network:

    processors:
      batch:
        timeout: 5s
        send_batch_size: 1024

      memory_limiter:
        check_interval: 5s
        limit_mib: 2048
        spike_limit_mib: 512

      # Add Kubernetes metadata
      k8sattributes:
        passthrough: false
        auth_type: "serviceAccount"
        pod_association:
          - sources:
              - from: resource_attribute
                name: k8s.pod.ip
          - sources:
              - from: resource_attribute
                name: k8s.pod.uid
          - sources:
              - from: connection
        extract:
          metadata:
            - k8s.pod.name
            - k8s.pod.uid
            - k8s.deployment.name
            - k8s.namespace.name
            - k8s.node.name
            - k8s.pod.start_time
            - k8s.replicaset.name
            - k8s.replicaset.uid
            - k8s.daemonset.name
            - k8s.daemonset.uid
            - k8s.job.name
            - k8s.job.uid
            - k8s.statefulset.name
            - k8s.statefulset.uid
            - k8s.container.name
            - k8s.cronjob.name
          annotations:
            - tag_name: component
              key: app.kubernetes.io/component
              from: pod
          labels:
            - tag_name: app_name
              key: app
              from: pod
            - tag_name: component
              key: component
              from: pod

      # Resource detection for cloud/k8s attributes
      resourcedetection:
        detectors: [env, system]
        timeout: 2s
        override: false

      # Add custom attributes
      resource:
        attributes:
          - key: service.namespace
            value: countly
            action: upsert
          - key: deployment.environment
            value: production
            action: insert

      # Transform processor for metrics
      transform:
        metric_statements:
          - context: datapoint
            statements:
              - set(attributes["deployment.environment"], "production")

    exporters:
      # Export metrics to local Prometheus instance
      prometheus:
        endpoint: 0.0.0.0:8889
        namespace: countly
        const_labels:
          cluster: production
        send_timestamps: true
        enable_open_metrics: true
        resource_to_telemetry_conversion:
          enabled: true

      # Export traces to local Tempo
      otlp/tempo:
        endpoint: tempo.countly-observability.svc.cluster.local:4317
        tls:
          insecure: true
        timeout: 30s
        retry_on_failure:
          enabled: true
          initial_interval: 5s
          max_interval: 30s
          max_elapsed_time: 300s

      # Export logs to local Loki via HTTP
      loki:
        endpoint: http://loki.countly-observability.svc.cluster.local:3100/loki/api/v1/push
        headers:
          X-Scope-OrgID: countly
        timeout: 30s

      # Debug exporter
      logging:
        loglevel: info
        sampling_initial: 5
        sampling_thereafter: 200

    service:
      telemetry:
        logs:
          level: info
          encoding: json
        metrics:
          level: detailed
          address: 0.0.0.0:8888

      extensions: [health_check, pprof, zpages]

      pipelines:
        traces:
          receivers: [otlp]
          processors: [batch, memory_limiter, k8sattributes, resourcedetection, resource]
          exporters: [otlp/tempo, logging]

        metrics:
          receivers: [otlp, prometheus, hostmetrics]
          processors: [batch, memory_limiter, k8sattributes, resourcedetection, resource, transform]
          exporters: [prometheus, logging]

        logs:
          receivers: [otlp]
          processors: [batch, memory_limiter, k8sattributes, resourcedetection, resource]
          exporters: [loki, logging]

    extensions:
      health_check:
        endpoint: 0.0.0.0:13133
        path: "/health"
        check_collector_pipeline:
          enabled: true
          interval: "5m"
          exporter_failure_threshold: 5
      pprof:
        endpoint: 0.0.0.0:1777
      zpages:
        endpoint: 0.0.0.0:55679